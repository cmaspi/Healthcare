{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "import biosppy.signals.ecg as ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = './Data/In-lab/'\n",
    "paths = sorted(list(os.listdir(parent_dir)))\n",
    "\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "def normalize_data(data, mode):\n",
    "    \"\"\"inplace operation\"\"\"\n",
    "    def minimum(data):\n",
    "        return min(min(data, key=lambda x: min(x)))\n",
    "    def maximum(data):\n",
    "        return max(max(data, key=lambda x: max(x)))\n",
    "\n",
    "    if mode == '0-1':\n",
    "        mini = minimum(data)\n",
    "        for subarr in data:\n",
    "            subarr -= mini\n",
    "        maxi = maximum(data)\n",
    "        for subarr in data:\n",
    "            subarr /= maxi\n",
    "    if mode == 'z':\n",
    "        raise NotImplementedError(\"not implemented yet\")\n",
    "\n",
    "def frequency_energy(data, sampling_freq, freq_start, freq_end):\n",
    "    N = len(data)\n",
    "    X = np.fft.fft(data)\n",
    "    freqs = np.fft.fftfreq(N, 1/sampling_freq)\n",
    "    \n",
    "    indices = np.where((freqs>=freq_start) & (freqs<=freq_end))[0]\n",
    "    energy = np.sum(np.abs(X[indices])**2)\n",
    "    \n",
    "    return energy\n",
    "\n",
    "def get_features(data):\n",
    "    \"\"\"\n",
    "    The selected features were mean, min, range, mode, low frequency energy (LF), 40th percentile,\n",
    "    60th percentile, 80th percentile, standard deviation of successive RR interval differences,\n",
    "    root mean square of successive RR interval differences\n",
    "    \"\"\"\n",
    "    feature_data = np.zeros((10), dtype=float)\n",
    "    \n",
    "    feature_data[0] = np.mean(data)\n",
    "    feature_data[1] = np.min(data)\n",
    "    feature_data[2] = np.max(data)-np.min(data)\n",
    "    feature_data[3] = statistics.mode(data)\n",
    "    feature_data[4] = frequency_energy(data, 250, 0.1, 0.2)\n",
    "    feature_data[5] = np.percentile(data, 40)\n",
    "    feature_data[6] = np.percentile(data, 60)\n",
    "    feature_data[7] = np.percentile(data, 80)\n",
    "    \n",
    "    rpeaks = ecg.hamilton_segmenter(signal=data, sampling_rate=250)['rpeaks']\n",
    "    rr_intervals = np.diff(rpeaks)/250\n",
    "    \n",
    "    rr_diff = np.diff(rr_intervals)\n",
    "    feature_data[8] = np.std(rr_diff)\n",
    "    feature_data[9] = np.sqrt(np.mean(rr_diff**2))\n",
    "    \n",
    "    return feature_data\n",
    "    \n",
    "def return_dataset(paths):\n",
    "    data = []\n",
    "    activities_list = []\n",
    "    labels_list = []\n",
    "    ema_list = []\n",
    "    for path in tqdm(paths):\n",
    "        dataX, ema, labels, activities = get_data_activity_chunks(parent_dir+path, sampling=5)\n",
    "        normalize_data(dataX, mode='0-1')\n",
    "\n",
    "        ema_list.append(ema)\n",
    "        labels_list.append(labels)\n",
    "        activities_list.append(activities)\n",
    "        \n",
    "        for act_data in dataX:\n",
    "            feature_data = get_features(act_data)\n",
    "            data.append(feature_data)\n",
    "     \n",
    "    return np.array(data), np.concatenate(ema_list, axis=0), np.concatenate(labels_list, axis=0), np.concatenate(activities_list, axis=0) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:10<00:00,  1.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "100%|██████████| 15/15 [00:11<00:00,  1.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|██████████| 15/15 [00:11<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 15/15 [00:10<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Adaboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SVM  Decision Tree  Gradient Boosting  Adaboost\n",
       "0  0.461538       0.500000           0.588235  0.428571\n",
       "1  0.545455       0.428571           0.705882  0.461538\n",
       "2  0.000000       0.666667           0.200000  0.181818\n",
       "3  0.750000       0.705882           0.666667  0.625000\n",
       "4  0.500000       0.333333           0.666667  0.823529"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=np.zeros((16, 4)), columns=['SVM', 'Decision Tree', 'Gradient Boosting', 'Adaboost'])\n",
    "\n",
    "\n",
    "for val_idx in range(16):\n",
    "    training_paths = paths[:val_idx] + paths[val_idx + 1:]\n",
    "    validation_paths = paths[val_idx:val_idx + 1]\n",
    "    \n",
    "    trainX, trainEMA, trainY, trainActivities = return_dataset(training_paths)\n",
    "    valX, valEMA, valY, valActivities = return_dataset(validation_paths)\n",
    "    \n",
    "    svm_clf = svm.SVC()\n",
    "    d_clf = tree.DecisionTreeClassifier()\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "    ada_clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0)\n",
    "    \n",
    "    svm_clf.fit(trainX, trainY)\n",
    "    d_clf.fit(trainX, trainY)\n",
    "    gb_clf.fit(trainX, trainY)\n",
    "    ada_clf.fit(trainX, trainY)\n",
    "    \n",
    "    svm_pred = svm_clf.predict(valX)\n",
    "    d_pred = d_clf.predict(valX)\n",
    "    gb_pred = gb_clf.predict(valX)\n",
    "    ada_pred = ada_clf.predict(valX)\n",
    "    \n",
    "    df.at[val_idx, 'SVM'] = f1_score(valY, svm_pred)\n",
    "    df.at[val_idx, 'Decision Tree'] = f1_score(valY, d_pred)\n",
    "    df.at[val_idx, 'Gradient Boosting'] = f1_score(valY, gb_pred)\n",
    "    df.at[val_idx, 'Adaboost'] = f1_score(valY, ada_pred)\n",
    "    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./Results/loso_chunks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
