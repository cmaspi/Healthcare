{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:44:16.425807: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:14:17.963502477Z",
     "start_time": "2024-03-29T04:14:15.829218454Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "parent_dir = './Data/In-lab/'\n",
    "paths = sorted(list(os.listdir(parent_dir)))\n",
    "\n",
    "data = []\n",
    "interval_duration = 1\n",
    "vec_size = int(15_000 * interval_duration)\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    temp = get_data(parent_dir+path, interval_duration=interval_duration)\n",
    "    dataX = temp[:, :vec_size].astype(float)    \n",
    "    remaining = temp[:, vec_size:]\n",
    "    # # z score normalization\n",
    "    # dataX -= dataX.mean()\n",
    "    # dataX /= np.std(dataX)\n",
    "    # 0-1 normalization\n",
    "    dataX -= dataX.min()\n",
    "    dataX /= dataX.max()\n",
    "    temp = np.concatenate([dataX, remaining], axis=1)\n",
    "    data.append(temp)\n",
    "\n",
    "\n",
    "data = np.concatenate(data, axis=0)\n",
    "\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "dataX, dataY = data[:,:vec_size].astype(float), data[:,-1].astype(float)\n",
    "trainX, valX, trainY, valY = train_test_split(dataX, dataY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:14:26.482871964Z",
     "start_time": "2024-03-29T04:14:17.969112521Z"
    }
   },
   "id": "e9df8f718efd332d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parent_dir = './Data/In-lab/'\n",
    "paths = sorted(list(os.listdir(parent_dir)))\n",
    "paths = np.array(paths)\n",
    "np.random.shuffle(paths)\n",
    "training_paths = paths[:-4]\n",
    "validation_paths = paths[-4:]\n",
    "interval_duration = 0.25\n",
    "vec_size = int(15_000 * interval_duration)\n",
    "\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "def return_dataset(paths):\n",
    "    data = []\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        temp = get_data(parent_dir+path, interval_duration=interval_duration)\n",
    "        dataX = temp[:, :vec_size].astype(float)    \n",
    "        remaining = temp[:, vec_size:]\n",
    "        # z score normalization\n",
    "        dataX -= dataX.mean()\n",
    "        dataX /= np.std(dataX)\n",
    "        temp = np.concatenate([dataX, remaining], axis=1)\n",
    "        data.append(temp)\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    dataX = data[:, :vec_size].astype(float)\n",
    "    dataY = data[:, -1].astype(float)\n",
    "    dataX, dataY = unison_shuffled_copies(dataX, dataY)\n",
    "    return dataX, dataY\n",
    "\n",
    "\n",
    "trainX, trainY = return_dataset(training_paths)\n",
    "valX, valY = return_dataset(validation_paths)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4674d676edb0190"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataX = data[:, :vec_size].astype(float)\n",
    "dataY = data[:, -1].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:14:26.949272503Z",
     "start_time": "2024-03-29T04:14:26.944010589Z"
    }
   },
   "id": "be4cc576ad3acda3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1131, 15000)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:14:26.977162376Z",
     "start_time": "2024-03-29T04:14:26.946706766Z"
    }
   },
   "id": "fc44887f7074d8a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(np.arange(trainX[0, :1000].size), trainX[0, :1000])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb2359c2480384e5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from model import get_model\n",
    "import tensorflow.keras as keras\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:14:26.996170806Z",
     "start_time": "2024-03-29T04:14:26.968537416Z"
    }
   },
   "id": "350b26e00f155ef1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15000, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 14998, 4)     16          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 14998, 4)    16          ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 14996, 8)     104         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 14994, 16)    400         ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14994, 16)   64          ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 14992, 32)    1568        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 14990, 64)    6208        ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 14988, 128)   24704       ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['conv1d_5[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d_5[0][0]']               \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 256)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_max_pooling1d[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 24)           6168        ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 24)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            100         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            5           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 39,353\n",
      "Trainable params: 39,313\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:44:26.982752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(input_size=vec_size)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:14:27.213599982Z",
     "start_time": "2024-03-29T04:14:26.975270631Z"
    }
   },
   "id": "e477f12efecac5ab"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            classes=np.unique(trainY),\n",
    "                                            y=trainY)\n",
    "weights = {\n",
    "    0: weights[0],\n",
    "    1: weights[1]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-29T04:14:27.253466161Z"
    }
   },
   "id": "e5654c091b9a9f0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:44:29.310418: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 122798080 exceeds 10% of free system memory.\n",
      "2024-03-29 09:44:29.339738: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 122798080 exceeds 10% of free system memory.\n",
      "2024-03-29 09:44:29.357995: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 245563392 exceeds 10% of free system memory.\n",
      "2024-03-29 09:44:29.447934: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 245563392 exceeds 10% of free system memory.\n",
      "2024-03-29 09:44:29.527114: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 245563392 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 41s 1s/step - loss: 0.7230 - accuracy: 0.4836 - val_loss: 0.7091 - val_accuracy: 0.3148 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 39s 1s/step - loss: 0.6971 - accuracy: 0.4916 - val_loss: 0.7193 - val_accuracy: 0.3148 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 37s 1s/step - loss: 0.7013 - accuracy: 0.4978 - val_loss: 0.7541 - val_accuracy: 0.3148 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "34/36 [===========================>..] - ETA: 1s - loss: 0.6848 - accuracy: 0.5221"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=1e-7, min_delta=1e-4)\n",
    "\n",
    "history = model.fit(trainX, trainY, validation_data=(valX, valY), verbose=1, epochs=100, class_weight=weights, callbacks=[reduce_lr])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-29T04:14:27.253661054Z"
    }
   },
   "id": "d5d9e5f7909e5d58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.predict(trainX[:10]), trainY[:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebfa74e9e2895254"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1500), trainX[1, :1500])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5895d1189e057443"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.arange(200), valX[1, :200])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b956ac22468780b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea1b6a3ee1ad114"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
